{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb551093-6b77-4d31-93df-80cdcaf61825",
   "metadata": {},
   "source": [
    "# OpenAI: tiktoken"
   ]
  },
  {
   "attachments": {
    "2e6f2630-5b19-4518-a449-4e9dec921e96.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV8AAACRCAYAAABkILvxAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAACPISURBVHhe7d0FXBR5GwfwnwEiKp5iYBc2iNj5CiYWKgqeZ57d3XfmhYF9tmfc2d15dgeKqOipmBigIiGCYNw7z8PsuiAooDCCz/fzWfnvzOzuuDPzzDPP/GcnxX8KCCGESFQp1b9CCCESkQRfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQQJyD7+AhQ1GgoGWsHjRtbCxYsJCnL21bFpevXFGHiq+Rv38AJk12ReUq1XiZFS5cFA0aNsamTZvx6tUrdSrgwIGD+vWA2kKIyCTzFbF28tQp1G/QAPPnL4CPjw8Pe/P2La5du4ZBg4fgx46d8PTpUx6e1IWEhKB167a886C/9FyILynOwXeK62Tcue2lfwwf9j67/XPRwkjjaFqRPHh6XkXfvv3h6/sEefPmwfK/l8Hr5nVcvnQRbdu0RqpUqXD69BmM/+VXvHnzRn2VECImkvmKT6LsdtGiP+Hn54f06dPzTrVatWoccOn56NGjUL++A0+7f/8BuLmd57YQImYJGnwpA9qwYSPs7GvBsnBRrg86O7fEkSNH8albx7148QJt23Xgwz4raxvs2rWbX0N1xb//Xo7q/7PjccVLWKFvv/54/Pix+srI9cZVq1bzeJqOPr9rt+548OCBOiX4Pc+ePcfzReNpPml+6TMMa5jfsrt37uLU6dPcrlWzJmzLlOG2TurUqdGq1fdo1qwpZ8Q2NqXUMRF8fX0/ugwILb8RI3/iZa1b5vQ8NstVd24hODiY69HlylfkaWhcp85dcfOmF483RMNoHE1D09L6pFvmdN6hStXqXGYh9LekValI5YfPWQ918xt1HqiOTvNP/w+R/CVY8KWVdMDAQRgydBju3buHt0r2RBmU2/nzygrXhTOpmAIwBd6evfrg+PHjMDExgavrJDRoUJ9Xyi5du2PM2HH6jZc2gu3bd6CZU3NcvXqNhxn66edRPJ6mo8//55/96D9gIH8G2bZ9u7JRteH5ovE0nzS/9Bk9e/bWT/ct87rlhSdPnnC7QoXySK1kvFFVqVwZ06ZOQbly5ZA2bVp1aIRPLQMPDw80dmyKNWvW4uXLlzyM/tJzCk6UcUc1dtx4/XuShw8fwql5C65H66ancQcPHlR24u1w4+ZNHkZ279kDxyZNeZzu9bQ+0TLvpax3umExofmO63oYdX7d3Nzg7NIy0jxQHZ3m36VlK/7/iOQtwYLv5s1bsHv3Hj407du3D65dvYIL593QtGkTDnDTZ8zEiRMn1KnfC1NWxN9+n6APvNOmTUF9BwcO1AuVgK0bPnHiBK45Hti/T8mmLLkWuXDhIt64DVWqVBEnTxyD55VLcHJqxsMuXbqsPC4pO4hQJTPfxK+pWLEC3C+44eaNf/HXsqXIly8fLHJY8Px/6+7dvae2gOzZs6ut2PvYMqDAM2PmLA6YFhbZsX3bVl6ugwYO4OnoZN45JVBFZWZmhqVLFvO0rpMn8bpBmSSVQRYumM/DZ86cDiMjI143KOATCsLjlEBIn0vzdfTIYV7mgwcP4mV95OhR+Dz24fmlHQqhvzTvK1cu5x1LfNZDw/mlss2GjZsQGBiIAgUK4NDB/Tx8x/ZtsLa2RrZsWfm9RfKWIMGXgtqevfs4yJYubYPOnTryypQp03fo0b0bzM3NeeU/cPCQ+ooIr1+H4+dRY7B27TreaGijosBLAgICuJ5IXFyc4eLcgjeWggULKhlqDx5+9tw5PHr4iNs67du3Q44cOWBqaoo6dWrzsNevXyufH6bM3xuEhkYcRtLh4rFjx3mDqF69GrZt3Yzx48by68Tn+dgyoPVi0cIFOHH8KP5ctAhWViV5udawq4GMGTPytIbBX6dL506wU6ahaVOkSIHRo37GmdMnlcP7FbCvac/DK1WsiJzK55I7d+7wX1rGFCApSA8ZPBh58uTmskm7tm1QrVpV9O/Xl+vZMYnvemg4v7Rd6MoXz58/x1FlnujIolixolitzP/8eXN5GxHJW4IE3+DgF/C+f5/b+fPnR4YMGbhNcuXKBUvLQtz28rrFgVqH2tevX+c2bZzXb9zQlyYeKIdhunoa1doKFiqsr6cNGDCIhwcGBigrsS+3dYxSG6mtyG1CG2DdOnV4g7h/35trclQvLFHSGgMGDoa3t7c65bctX/58aiuifhtXH1sGhIIfrSN02D1mzFg4OjZFq1ateUcYE0tLS7UVgZYhBesg5TVTpkxFC2cXONRvgHvqeqhDmTQxz5wZuXPn4jahz1+2dAl69+7FSUJM4rseGs4vzSudoKQdD/0f6f9MNeZixUqgQ4eOuCJ93b8JCXrCLTp0Ei4sLEx99iFaIXUZz/LlK+DhcYnbsUHBOzAwSH32aZQxdVKy8oUL53NWotvoKCunWlyrH1pHqhV+qywLWSqHwtm4TScnox5SEzopNXDQYK5lxqWrGe1cl69YySebOnfpir+VZU4nvHS139g6fPgIB7A2bdvzRTvnz1/gC0K0EJv10KFePSXLXQnHxo2RJUsWHkbfK517oBPNVNYQyVuCBN/06TMgT9683L57926kk1aUOXl7R5ykoAzY1PT9yRnKCAb078e1MQrAlBVMmjyZX5/DwgKZlWyF9FMODQ37Exs+atWqydPEFh32FSpUiD+TatKXPNw5+6F5ocNTbyUj/tblL5AflStV4vYBZafkfuECt3Uo2K5evYbr/BQ4Tqs9I2Lj1q3bmD17DgdbqndSX/FTJ09g44b1+p3wp/j7+3MvAVqW1AeZaqrHjx3hem4+dT3UKWNry3/9lGkfPHh/UovWse49enK99mO9Db7UekifkTatCdelz509jX+veeK3X3/h5IN2/tSvWiRvCRJ8KaA61KvLAeziRQ/8uXgJr1CUicxTz0bTIX8DtW+oDg2rXKUy14nbtm3Dw86dc8Padeu5BmZvb8fDViiZEmU6VDsjly9f5jPPVLLQDYsN6tXQXjnMc3JqgS1btnJGbmpqiqxqJkJ1ZxOTNNz+llHvhi5dOvMyoKBBXaUoM6Pvmp6PH/8Ln1wltWvXQiU1UMdG6KtQ/ZFQ3Tq1+QjEzCwDDh0+rA+C0WXahqhEFarWUCtUqICGDRvwiUE6oeur9tKgeaUsu2rVKsiZMye/t+uUKVxCoJ0HZdxUy53sOgVbt25TXpECKZX/N3n27JkSnCPm5Uush1Q37tO3H5q3cOHeDRT4jY2NkTVrVi7BEMNSnUieEqzs0LKlC5+QoJVw1qw/uC9jmbLlOMhRUO6jZJfULSk6VA7o0L4dihcvzq+nFZS67+hOhlDwpktZqU8u1docmzTj+tuvv01QDvlifxlocPBLJeMK5oyJusUVK16S35M2IPrcypUrwVbNlL51JUuWUJbjDCWoZeP6OGW49F1ZlyrNZQP6vqj3AJ340gWQ2KATYhQMydRp0/k9qU8tZcO6AEY13I/9PgT1JChStAi3qV85rWuFixTjfsK00ye03lFWS71Yfv55JGeYdEUelSpoWvoM+rz/Va8OR8fGnEDozk1Q6alS5SrKjqEmXz79ueshzRMd1VG2Txl7KRtbrh1T/2faKRQpUgQ1a9qrU4vkKsGCL22A1FuA+n4WKVyYAy5lUOXKlsWqlSs4k6IgGxPKMAYO6M8bCa3k06bP4PdYMH8uRo4Yjty5c/N09J4UpMePH4dFC+fHKWOggLJzx3aMGD6MN0p6f0LvPW7sGOWz5nEmLCJQl6v9/+xD9+7dYKEcfhPd9z91iiuXbih7iwtazgsXzEPdunV4WdMyoGUxffpUjB0zGunSpVOnjBm9bvKkiWjd+gf99DR/tJ7MnTtbXybQoR4027ZuUQJcTX4t0S1zml63DvXs0R2NGzfST2Ocxpjnj8Z/znpI80b1XvrO6DX0WkLfBX23Gzes03+/IvlKoRyKffxSMyGEEF9covd2EEIIIcFXCCE0IcFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE0IMFXCCE08Fm/50t3F6CbHsYV3acrrvdaE18XuvXOkSNHsWLlSr7Vk+6Gl3QzSPrR9bbt2sC2dGn9D9TH1e49ezBw4GD9nSiIrDciOfmszDc+txEXSd+ZM2fhUL8h73jpHmaGdxqm+51t274dzs4t4ezSEnfu3FHHxN6DBw/g6jo1UuAVIrn5rOBreFdi8W3Ys3cvOnXuglu3bqlDYubufpFvv083lowtCrjjf/k1XkFbiKTks4Kvj5r50s0G169bE+0ttKN7yKFj0uTh4YGffx6tz3Tp3mgTJ07g2+3Tcr15419eD6pWrcrjCd1+n25ISneujo0VK1fh4MFD3KYbctrY2HBbiOTmi2S+RkbGSKPeZFAkT1Tj/XPxEr6ZKSlc2BKbNq5HSxdn/c0i6aapdEfqZUsXo1PHH3kYuXTpMt9q/lMouNOdqukuwgUKFMCY0aOQTm5gKpKpeAffkJBQzmqImVkGZM2Shdsiebr27784diwigNLdfOkW8XSX4ehQEO7VqxdsbUvzcwqmVK54o94KPjq0I584aTIHd3r/IUMGIW/evOpYIZKfz8h8/8M7dWNKndqINziRfF1WstfAwEBul7G1RZkyZbgdk0yZvkO9unXVZ8Dt23fwIihIfRYZdbiZMXMWTp8+w89/+KEVHOrV47YQydVnZL4heOzjw+0cFhYwlcPDZM3w5GqevHlitbwtLS3VFhCqrC+vX79Wn0VGWfGqVau5TXXe/v36IkWKFPxciOQq3sH33bt3+szXJG1a5d8UOHnqFH7s2AlW1jYoUNAShQsXRe069TB16jQ8eRJRohBJX548edRW7KVMlQopU364uj18+BDTp8/gXg7m5uYYPmyovoYsRHIW7+D77JkfgtRsKEzZcLp174HWrdtG6vdJNT7qkjR7zlxUrVods2fP4RM3IukxDIheXl5cKvgUmk6HTqBFDaq0LlCd9+ZNL74YY0D/ftK7QXwz4h183757y9kvOXHy5CfPZlMgnjptOkaPGSsBOAmyLmWNjBkzcvvq1Wv6Xg8xoTLFP/v3q8+ACuXLIU2aNOqzCMv++hu7d+/htouLM1q2dOG2EN+CeAdfPyXzDQ4OVp8BqZXMxcmpGXbt3M79Panf54Xz57gfKPUH1Vm3bj3Wrl2nPhNJhbWVFS66n+flunfPLr6M+GO2bduOixc9uJ0zZ044OEQ+gWbYrYy6rfXq2UNO2opvSryDr3kWc5QoXhzp0qXjjGjBwvmYOsUVxZVhuo0oU6ZM3A+U+oPSBkZoY/t7+Qq+DFUkTxRYp8+Yycuaygk//tghUre0qN3KqNtarly51LFCfBviHXwpE9q2bQuuXPaAm9tZ1LS3V8d8iDa8yZMm6Q9bqQ586tRpbovkxdPzKvr2668vS1A5oUP7dtwmht3KdHVewyvihPhWxDv4GqKSw6dYWVvBrkYNblNGdMHdndsi+bhwwR2dOnfG/fve/LxatWoYMXxYpHKCYbeyypUro1Wr76VbmfgmfdZPSsbV4iVL8euvv3G7Zs2amDvnjw9Owoikh1ahzZu38MlUXU8Xezs7zJw5PVIPB/p9h3bt2+PKFU91yOehI6nly//iozAhkprPynxpo6MsNrbyG9T9XoWGxum14utEPVcmTJyEocOGc+ClUkLr1j9g7tzZH3Qte/06HC+C5JfwhCBxDr50Zdu06TPQqLEjSlqVwqFDh9Uxn3b33j21BXyX6TsYS9abpAUEBHB9d9GiP3lHSifPfv5pJMaNHcNtIUTM4pX5nnc7zydWQpXs9djx47HqcE/9fOn3AXQK5M8fq1qx+Dp5ed1Cy+9/0PfTzZ49GxYvXoQOHdrHePeKbNmy4fDhg/qfFv3Uw/PKJb4rhg7dycJwPHV9k5KDSKriHHxNTU1RvkJ59Rmwdes2eHhcUp/FzP3CBRw4eJDbRkZGqFy5ErdF0kI72v37D6CFswtu3LjBw0qXtsGG9esiBUohxMfFK/Nt0KA+ZzqEfulq6LBhuGdQUoiKsqRhw0fqL8qws6uBsmXLclskHVTfnTNnLnr06MnLnTJc5xYtsHLFcuTOnVudSggRG/EKvkUKF0bnzp31h5d0bb5Tc2csXLiIf+OXsiN6UHvWrD/QtJmT/rYw9OMpdDWT1ASTFl19ly4RpxKSrr47YcJv8ot2QsRDvLuaURY02XUKlixZGuteC3Q13JQpk+W3WpMY+uH83r374NDh2J9cjQ79Ylm3brG/2zWd3O3SpRv/Wh6RuxeL5CRemS+hjvPDhg7BtGlTIv12Q0xKliyBDevXSuBNkv5DWFiY2hZCfAnxDr6Eyg6OjRvj2NHDmD5tKsqWLcN3MNChH1+h8euVoLt1y2YUK1ZMHSOEEN+2RL3CTQghRITPynyFEELEjwRfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQgARfIYTQQLzu4fbu3Tu8efOW/wohhIi7OAdfCrjh4a/VZ0IIIeIjzmUHyniFEEJ8njgHXyk1CCHE55MTbkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoQEJvkIIoYE4/57vq1dhaivuPE+HqC1tBZX6V219WZWePVRbgrzzNFZbYkupmmpLxFXzXEZqK3mRzFcIITQgwVcIITQgwVcIITQgwVcIITQgwVcIjeybPwPzu7bCkzte6pCvX1Kc569Vogff+w9vYdC4dvhr/R/qkC8rLPwVZiwaww9qx8aRDUcxrMFIuB+6qA5JHH4BIWg1eAVqtJsT6XHS/a46xbfppNdt2E+azn+/lIk796L1gqXwC36pDhG3L5zFzNaN+a9IfJL5KkxMTSL9FSIx1O3eH90Xrka2ApbqkK9fUpznr5UEX4WZuRmMTYyRNn3iBl/z70yxekobHPm7Fz8mDGiojhFCJHeJfpEFlR1m/jkOpUqUR3vnPuqYj3v8xBtrti7Cnfs38PbtG2TPmgsNa7nA1qoyUqZMyeWFeX9NwPVbl9VXRK9H+xEoVbz8BxdZ3HT3whrXdeg4vj1yWeZSh0YW8DQQB1YfhMeRSwgLDUOatGlQyKYgHDrUQ/a82Xiaz73IgsoNI6bv5CBcxTa/OjSysPA32Lz/Mjbsu4Snz4NhamKEmpUKo33T8siWOb06VYSXoeFYuuks9p64jqDgVzBTdi4O1Yqio1NFpFVep7N65wXMX3tKfQaUKZEbo3rUwYa9Hth19Br8g0JhmTcLpgx1hIlxaoycsQs+z15gWCd7LN1yDpdvPEbqVCnhaF8SnZq/f++4XGRBJYafNm5Vn0XPNl8e/ObUBGmNI96fVtyL97yx4PAxeD15ysOK57RA1xrVYJ078nKkssPlB48wq7ULzNOn42Evw8IwdstOXH30GEPq10GNYkWQgsco3/ObN9hywQMb3S7g6QvlezY2Rs3iRdG2SkVkM8ugTvV+vjtWrwITo9RYddoNASEhKJA1C/rVsYdNntw8HV1kQXXSTRNGIexlMA8jadKlh9OIXz7IJKObNqrGg0ahYJkK6jPghd8znFizDHcunEX4q1Ckz5wFtvWboHS9RkiZKjVPQyWG7VN/4XZM8pQshcYDR8HIxCRO86zz/KE3Di2bDx+vf/FW+R4z58yNSs1bw7J8ZSXi6L5h4PyOjTi+ehkceg2B7+0b8Dy0D6/Dw5DDsihqd+2HTDkilqFcZKER9yunMXnOcNy4dQWvX4fj3bt3eOzrjSVrpuPA8W2I474jWqYZ0nL2m/67yMFLx/eeL+YMnIeze85x4CX09+rpa/ij7xx4HL30RebjU16GhGP0H3swb81JDrwk5NVr7Dh8FUNct8NXCYg6FDAHTtqK9UoApcBL6O+6PR6Yt/akshN7x8Oi8zIkDD/N3I2VOy7w+xD6nHfv3v8f/QJe4udZu3Hx2kN+L9op0Gd96r2/pE1u7hiybhOu+/jirbJe0OOKEmCHrN2Eo9dvqlNF740y7XwlaF9+8BDDGtSFnUHgpaA8ZssOzD90lAMvCQkPxw6Pyxi6fjN8g4J4mKHNFy4q0x/jwEvuPH3Ggf2m7xN+Hh8pU6VCBvOsyJjNAnmtS8OqpgOs7OshXabMPMwsa8ROn1DAWz9uCK6fPMKBlwQ/f6YEt6W4uHcHP08MFNzXjh6EB1cv4Y3ynf2nfM9+D+5j1x+TcH7nZmWP+eF2cmzlYrjv3srzTdM/unENO2dM4PlPzr7qzDcoOAAzF43Fi5eB+L5JF9iUqKjsOFPA+9EdLFWC76uwUPTvMg4W2SKyC6LLggllummMPywlxPXy4jO7zmLT7C2or2S55R3KIZ1ZROb03MdfyYYPoFrTashRwCLBM1/KeGf8fRS1lEy3+/dVONOlgLxmtztWbD+PZrWt0bdNdZ52/6kbmPbXEbRzLAenOqVgbJQK9x8HYJQSMEOUjHjmyGbImc2Mp9UJVQIsZbUXrj5Alkzp0PuHaqhapgC/VsdwmtLFc2F455qwyGKGc1fu4/cF+2Ga1hizlPem18f38mJdNvlb8yaoYllQHRrZ3Wd+GKwE2XAls+pT2w72SlZK9l25ijkHjiBrhvSY7OKkz1INM9+Mpmkxe/9h7FWmHapkvHbKa9/nY0qWqmS8M/85yJluN7vq/B4UkNeePY+Vp86iaZnS/JlEN69pUqdGb2WYg3VJhL9+gxnK6//xvMav/75iuWgvL6bM79y2DR/NIg29U476Di1bgNtup9B48GhYFCqijgFOb1zJQbZW594oVLaickSYSg1iv8NMCdRNh47ljNWQLguOmkF/zMfmOSQoEJuVLDnA5yEqNmsFm7qNkFo5Yrh/2R3/LJrFwdjwdbrM19QsI+p0H4B81rYI9n+OffOm4eF1TzQaMFKZr4qS+Wrh7v2bSjb3EC0adkAZ6ypIpWQCVGbIl7sQGtRyQeALfzx+8kCdOuFYKIHVxDQNdi/bi/Hf/8Y9Iyb+6Ipz+9xQp00dDrwJjYLeUbfbKGFpgf7t/qcvMaQzNYaLQ2kUK5ANt+4/4wyV1K5cBDvmdkbL+rb64Jk3x3dcdggNe40XSnYbkwzp0uCXvvVhX9EyUuA1lMksLfq3/R9yZDXjI8nyVnlRqXR+zq79AhP+NzwoY/ULDubD/ToliyO1sl7Qo34pKzQvZwvv5/7wevJh1km5xoZzF7Dr0hXltZU/CLyh4cr3fOMmSuTMgX51auqDd7o0aeBcvgyK5siOW0+eciZsqIHyuQ1trHkeTNMYo4UyDxmUw3baSXwJFHjPblmH6ycOw/7HnpECL6HD+m7zV6Jw+SoRJQZloeQsWgL5bMoh9EUQ3ihHjQnt2f078H/kjZJ2dVGucXMuW6Sg7dWmLKp93wHhoSHw9vRQp36vglMr5FemoWkzmGeBbYMmPNz/UcJv21r6qoOvz9MHyiHsWyxdOxM9hjtFeixdO4Oneer3mP8mpHzF86LntB4obWejL034+/rj4JpDmNZ9Bq6c8ORhCYmCKtVZr3r5oHHPxZG6pjXq8Seu3vLFk+cvOUjr0FGCr98LbDvkifFz93G3tkUbzqhjY1Yojzny58qsPoteWhNjriHrUADOpwT3xHL32XMObiVyRt7xUSClOmsqZUO+7+cfMdAABdZlx0/BKHUqJZBaRAq8hIKqb6DyPT96jCaz5nGXN93DceY8XHvkw6UICtKGKEgbvpd5+vQ8f1+EssNw370NbtvWo1ILtXYag+dKwDq/YxN2TP8di3t3wL8nDqljEl6grw/XePMqGSyvEAYo2zU1+w5+D7zVIe9RacVQ+kzmME5rqj5Lvr76mq9p2vQY0ccV8yZuivZRt0YzdcqERSfVWg1tiVGrRuL3bb9gyJ+DUKuVvZKRvMPpXWcQ/irhMwviUK2YvndE1Af1nKAeFIRqwn1/34yfZuziWq2zgw3mj2mBzs0r8viPoaOLqEEpOfAJDOS6bI2ihZHWyBiz/jmkr9FGVc+qBA4NGxDtY2W3H/Un7RKD17lTOLNpNSo7t0WZ+kpWGCWwkad3b2PF8N44/NcCmKTPoEzbGm0mz0GxqvbqFOJr81UH36zmORASGoxrNz0+OKHlH+iHew+8ODNObKmUrClLTnPYtaiBvEpW7P8kIMGDL/UgyJY5HTyVzJcyYEP01Xhcf6R8JxGBhE54Ue8Fqj1OG9YETWtZoXjB7MiYwSTSSbOkLH+WzHjx6pWSofqoQyLQ/87DWzlievcOec0zRQw08EOl8hjSoC662VXjk2LLjp/maXWoJwXViz2VzNcnMPKJNXrvS94P4f8y8X4a1evcSfyzYAaKVrWDbX3HaANvWMhLHPprPjLnzIOmw8Yqh/11YJ47H9Io2eN//yXOyU+SMbuFsm2k5hovr5QGqNdESFCAMl951CHiqw6++fNY8sm0nQfW4fCp3XwyjYIwlRqWrZ2JGYvG4t7D6C9zfOR7H153rnLvCBL8MgivwuK+0dDnUW+G7Qt3Ijz0fYB9E/6Gr4i7f+0+subKkuAXaFCXsko2+eDtE4DfFuzH3YfPef0Of/0W2w97cm+H2atOcOClYc+VQPzM/yUePw3ST7f3+HU+OZdUHP73BoJCI3pqUO+E5y9f6gMldSWjQ/slx5Tg5HmNx9Nj96Ur2OjmjjyZM8Ey2/veAMQiY0Y0Ll2K67J0gq6BjRX2XPbEiZu31CmU79nYGJUKFcCD5/6YsGMP7j3z46BLJ/Z2XLyEoes2Yc7BI5ECdkLxuXUDh5bMhUXhoqjWqoO+u1hUb8LDEBIYgKBnT5RHRJc7Cshu2zfC6+wJfv4xN88cx6vgiB061ZZDAvyVv3FParLkLYBMyg7A8/A+/uzXys6Rei/c8ziP42uWcSkhT0kbdWqhWW8HymhjouuPS9yvnOKaL3UzM0SHxk0d2qB29SZKMhA5GzhwbBs27f5bH3h1Yurn+zFv37zFtgU7cHb3uQ/ej1ANuMOYdshTNHecezvQ5cW9f92ER08C1SEfypktI2b/7MTlBO5qNnsP3K58WDejGu3kQY2QPUsGDrZzVh3nrl9RmaQx4j65U4c6oljBiOAUtZ9vVFTqGNG1Frd1vR0o+9bNlw69D3VPm6pk20XzZ413bweqqQ5bv5kzU0NR+/lSkJ136OgHgZB6Hoxs5ID/FS2sDom+ny91GRu2fgu3Jzk3RXaziN4fuv6/bnfv8XND+bKYR5pW19tB16tBhy5j7rtynbKTyInhDevF2M83Kl0f21fBQdgyeayyww/lngi07oUGBfJJLdpkQwL9Ub/PMB5HvQh2z56M2+cj1/PpBFaq1EYwzfgdnEdP5H6/hqgr15ZJY+H3IPL/81P9fKMynJ56UOydM0Xf3U2H5qVqy/Yo27CZPnvX9XaI2ttC95nlHVugbKPm0ttBK3QhBdV8rYuXg5GRMQfdHNnzoOP3A1CrmuMHgZfYVWkIl8adYJ4pIrjQa6htahL3Oh2VGJr2dESPqd1QolJxvriCGCkBoHiFYujh2pUDb2Kgng2/92+Afm3/BwslyBLKiBvZlYDrkMYceAl9JXSxQ+tGZZDeNGJ+qXcCPZ8/tgW/ttvY9V/tb0jQYf/4po1QuVBBDqSEMlIKeKlSvl/eTuVs4erihKIW2fkEGz2slGDn2tIpUuCNCb1f1xpV4RMQiL+On+bMmVDPhl+bO6JvHXslW44IsvT5jWysMdm5mT7wJqSn9+9y310KkJf278KVg3twy+0UAp/4IOipLwdcHerOVatjLy43UJtQH+Aa7bqi2YhflATiNVYM78NBzRAF44b9R6CAbXn964xN0vIJsJTKDjo+KIi2HD8VuUsoRxjKe1LQNc+dFw2UHYVh4BXKV5HYme/XQG4jlDjkNkLvyW2E4k8yXyGEEF+MBF8hhNBAopYdhBBCRJDMVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghNCDBVwghEh3wf5C6h3mRrFuzAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "4d3f9383-f9b1-4382-9c6e-337dc921c6d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "* tiktoken is a fast BPE tokeniser for use with OpenAI's models.\n",
    "\n",
    "* A helpful rule of thumb is that one token generally corresponds to ~4 characters of text for common English text. This translates to roughly ¾ of a word (so 100 tokens ~= 75 words).\n",
    "  \n",
    "![image.png](attachment:2e6f2630-5b19-4518-a449-4e9dec921e96.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c563258a-360b-4b18-82ab-5f9787500aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dfee04c-a9e7-45b3-a2b9-6f5da4d4c0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2fa44e4-b8e7-4f91-952c-a8e3a2688b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, encoding, model):\n",
    "    encoding = tiktoken.get_encoding(encoding)\n",
    "    encoding_model = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    encode_token = encoding.encode(text)\n",
    "    num_tk = len(encode_token)\n",
    "    decode_token = encoding.decode(encode_token)\n",
    "    single_token_decode = [encoding.decode_single_token_bytes(token) for token in encode_token]\n",
    "    \n",
    "    model_encode_token = encoding_model.encode(text)\n",
    "    num_model_tk = len(model_encode_token)\n",
    "    model_decode_token = encoding_model.decode(model_encode_token)\n",
    "    single_model_token_decode = [encoding_model.decode_single_token_bytes(token) for token in model_encode_token]\n",
    "    \n",
    "    print(\"\\n\\nEncoding name {} based results: \\n\".format(encoding))\n",
    "    print(\"Encoding: {}, tokenwise_decode: {}, number of token: {}, decoding: {}\".format(encode_token, single_token_decode, num_tk, decode_token))\n",
    "\n",
    "    print(\"\\n\\nOpenAI model name {} based results: \\n\".format(model))\n",
    "    print(\"Encoding: {}, tokenwise_decode: {}, number of token: {}, decoding: {}\".format(model_encode_token, single_model_token_decode, num_model_tk, model_decode_token))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9d5f36-36e2-4c46-938f-d50e86c6e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Encoding name <Encoding 'o200k_base'> based results: \n",
      "\n",
      "Encoding: [1347, 885, 4484, 6602, 2860, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "OpenAI model name gpt-4o based results: \n",
      "\n",
      "Encoding: [1347, 885, 4484, 6602, 2860, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n"
     ]
    }
   ],
   "source": [
    "text = \"let's learn tokenization.\"\n",
    "tokenize(text, 'o200k_base', 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabeff0d-74de-475e-bdb4-b73879f71bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Encoding name <Encoding 'o200k_base'> based results: \n",
      "\n",
      "Encoding: [1347, 885, 4484, 6602, 2860, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "OpenAI model name gpt-4o-mini based results: \n",
      "\n",
      "Encoding: [1347, 885, 4484, 6602, 2860, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "Encoding name <Encoding 'cl100k_base'> based results: \n",
      "\n",
      "Encoding: [1169, 596, 4048, 4037, 2065, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "OpenAI model name gpt-4 based results: \n",
      "\n",
      "Encoding: [1169, 596, 4048, 4037, 2065, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "Encoding name <Encoding 'p50k_base'> based results: \n",
      "\n",
      "Encoding: [1616, 338, 2193, 11241, 1634, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "OpenAI model name text-davinci-002 based results: \n",
      "\n",
      "Encoding: [1616, 338, 2193, 11241, 1634, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "Encoding name <Encoding 'r50k_base'> based results: \n",
      "\n",
      "Encoding: [1616, 338, 2193, 11241, 1634, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n",
      "\n",
      "\n",
      "OpenAI model name davinci based results: \n",
      "\n",
      "Encoding: [1616, 338, 2193, 11241, 1634, 13], tokenwise_decode: [b'let', b\"'s\", b' learn', b' token', b'ization', b'.'], number of token: 6, decoding: let's learn tokenization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_name = ['o200k_base', 'cl100k_base', 'p50k_base', 'r50k_base']\n",
    "model_name = ['gpt-4o-mini', 'gpt-4', 'text-davinci-002', 'davinci']\n",
    "text = \"let's learn tokenization.\"\n",
    "[tokenize(text, encoding_name[i], model_name[i]) for i in range(len(model_name))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cea40b-0f15-4591-a319-5370a802d7f0",
   "metadata": {},
   "source": [
    "# HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e5597-701c-47cd-9651-538ac364b551",
   "metadata": {},
   "source": [
    "### Normalization & Pre-tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6513a-d64a-4217-8368-e1eff83bd6a3",
   "metadata": {},
   "source": [
    "* The normalization step involves some general cleanup, such as removing needless whitespace, lowercasing, and/or removing accents.\n",
    "* The pre=tokenization splits the texts into small entities, like words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c1ea98-1ca5-4ffd-bc6e-fb7a3bef3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def pre_tokenize(tokenizer, text):\n",
    "    print(\"Tokenizer from tokenizer class: \\n \", type(tokenizer.backend_tokenizer))\n",
    "    normalized_out = tokenizer.backend_tokenizer.normalizer.normalize_str(text)\n",
    "    pretoken_out = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(normalized_out)\n",
    "    return normalized_out, pretoken_out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba1fb46-3764-4892-b3bd-06259bb3d568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer from tokenizer class: \n",
      "  <class 'tokenizers.Tokenizer'>\n",
      "original text:  Héllò hôw are ü?\n",
      "Normalization:  hello how are u?\n",
      "Pre-tokenization:  [('hello', (0, 5)), ('how', (6, 9)), ('are', (10, 13)), ('u', (14, 15)), ('?', (15, 16))]\n"
     ]
    }
   ],
   "source": [
    "# BERT tokenizer, the pre-tokenization involves splitting on whitespace and punctuation.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Héllò hôw are ü?\"\n",
    "normalize, pre_token = pre_tokenize(tokenizer, text)\n",
    "print(\"original text: \", text)\n",
    "print(\"Normalization: \", normalize)\n",
    "print(\"Pre-tokenization: \", pre_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f5d915-7363-49f6-8e45-237b8f580113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:  Hello how are u?\n",
      "Pre-tokenization:  [('Hello', (0, 5)), ('Ġhow', (5, 9)), ('Ġare', (9, 13)), ('Ġu', (13, 15)), ('?', (15, 16))]\n"
     ]
    }
   ],
   "source": [
    "# GPT2 keeps the spaces and replace them with a Ġ symbol\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "text = \"Hello how are u?\"\n",
    "pre_token = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "print(\"original text: \", text)\n",
    "print(\"Pre-tokenization: \", pre_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42126508-e2a2-4799-b104-80abaca67492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:  Hello how are u?\n",
      "Pre-tokenization:  [('▁Hello', (0, 5)), ('▁how', (6, 9)), ('▁are', (10, 13)), ('▁u?', (14, 16))]\n"
     ]
    }
   ],
   "source": [
    " # T5 keeps spaces and replaces them with a specific token (_), but the T5 tokenizer only splits on whitespace, not punctuation. \n",
    "# Also note that it added a space by default at the beginning of the sentence (before Hello) and ignored the double space between are and you.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "text = \"Hello how are u?\"\n",
    "pre_token = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "print(\"original text: \", text)\n",
    "print(\"Pre-tokenization: \", pre_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86997a3-40a2-4a23-bca4-a429895275df",
   "metadata": {},
   "source": [
    "### Wordpiece, BPE, Sentencepiece methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c60535a-710a-4a99-b590-0d51b80927e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert tokens:  {'input_ids': tensor([[  101,  2292,  1005,  1055,  2707,  4824, 19204,  3989,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Bert decode output:  ['[CLS]', 'let', \"'\", 's', 'start', 'understanding', 'token', '##ization', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# wordpiece\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Let's start understanding tokenization.\"\n",
    "encoding = tokenizer(text, return_tensors='pt')\n",
    "print(\"Bert tokens: \", encoding)\n",
    "decode = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "print(\"Bert decode output: \", decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07519c8c-836b-4c9a-889f-b4e3aac7ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 tokens:  {'input_ids': tensor([[ 5756,   338,   923,  4547, 11241,  1634,    13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
      "GPT2 decode output:  ['Let', \"'s\", 'Ġstart', 'Ġunderstanding', 'Ġtoken', 'ization', '.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# BPE\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('openai-community/gpt2')\n",
    "text = \"Let's start understanding tokenization.\"\n",
    "encoding = tokenizer(text, return_tensors='pt')\n",
    "print(\"GPT2 tokens: \", encoding)\n",
    "decode = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "print(\"GPT2 decode output: \", decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620e3e47-27fa-4d9a-aed9-f090d71f4db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLNet tokens:  {'input_ids': tensor([[ 2834,    26,    23,   467,  2172, 17366,  1822,     9,     4,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "XLNet decode output:  ['▁Let', \"'\", 's', '▁start', '▁understanding', '▁token', 'ization', '.', '<sep>', '<cls>']\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer\n",
    "\n",
    "# sentencepiece\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "text = \"Let's start understanding tokenization.\"\n",
    "encoding = tokenizer(text, return_tensors='pt')\n",
    "print(\"XLNet tokens: \", encoding)\n",
    "decode = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "print(\"XLNet decode output: \", decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4722df1c-a580-4075-95fd-9645875c9ae6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Compare GPT2 tokens and GPT4 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200d041d-bc27-4339-a3a3-29008307c76e",
   "metadata": {},
   "source": [
    "* GPT 4 combines more white spaces than GPT 2\n",
    "* For given example, GPT 2 has 10 tokens where as GPT 4 has 7 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806257bc-1cf6-4d0d-adca-3545aded12c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2 output:  {'input_ids': tensor([[17250,    11,   703,   389,   220,   220,   220,   220,   345,    30]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "token length:  10\n",
      "decoding output: ['Hi', ',', 'Ġhow', 'Ġare', 'Ġ', 'Ġ', 'Ġ', 'Ġ', 'Ġyou', '?'] Hi, how are     you?\n"
     ]
    }
   ],
   "source": [
    "# gpt2 \n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "text = \"Hi, how are     you?\"\n",
    "result = tokenizer(text, return_tensors='pt')\n",
    "print(\"GPT2 output: \", result)\n",
    "print(\"token length: \", len(result['input_ids'][0]))\n",
    "decode_result = tokenizer.convert_ids_to_tokens(result['input_ids'][0])\n",
    "decode = tokenizer.decode(result['input_ids'][0])\n",
    "print(\"decoding output:\", decode_result, decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f9b72d-48f8-4846-b746-527672065149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT4 output: [13347, 11, 1268, 527, 257, 499, 30]\n",
      "token length:  7\n",
      "decoding output:  [b'Hi', b',', b' how', b' are', b'    ', b' you', b'?'] Hi, how are     you?\n"
     ]
    }
   ],
   "source": [
    "# gpt4\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "encoding = tiktoken.encoding_for_model('gpt-4')\n",
    "text = \"Hi, how are     you?\"\n",
    "result= encoding.encode(text)\n",
    "print(\"GPT4 output:\", result)\n",
    "print(\"token length: \", len(result))\n",
    "decode_result = [encoding.decode_single_token_bytes(token) for token in result]\n",
    "decode = encoding.decode(result)\n",
    "print(\"decoding output: \", decode_result, decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d49b9-5423-4cfe-8f66-6d3da0348dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
